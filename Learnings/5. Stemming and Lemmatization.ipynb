{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bf89c4-57f4-40cf-af89-2961d41ee108",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" >Stemming and Lemmatization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb0e9a-7dd2-432e-91c2-7c770dbced52",
   "metadata": {},
   "source": [
    "In simple terms Reducing words to its base word\n",
    "\n",
    "\n",
    "**Stemming:**\n",
    "* Use fixed rules such as remove able , ing, etc, to derive base word.\n",
    "\n",
    "\n",
    "**Lemmatization:**\n",
    "* Use knowledge of a language (a.k.a linguistic knowledge) to derive a base word.\n",
    "\n",
    "\n",
    "-------------------------------------------------\n",
    "- NLTK supports both Stemming & Lemmatization\n",
    "- Spacy supports only Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d96647-59e4-4b61-b903-3538a0fb8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04dc6e8-c704-422e-817e-39b21f72b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer #other stemmer is snowballstemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ef11a8-0f99-46a7-9735-2bf4770aed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  ate\n",
      "adjustable  |  adjust\n",
      "rafting  |  raft\n",
      "ability  |  abil\n",
      "meeting  |  meet\n",
      "better  |  better\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\", \"better\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa665798-8034-4da4-a4f8-cbb28cfc1ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "    |    \n",
      "ate  |  eat\n",
      "   |   \n",
      "adjustable  |  adjustable\n",
      "rafting  |  raft\n",
      "ability  |  ability\n",
      "meeting  |  meeting\n",
      "better  |  well\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"eating eats eat   ate  adjustable rafting ability meeting better\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.lemma_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fba36ed-3149-4e49-84b9-f56d28f7b862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  |  the\n",
      "mother  |  mother\n",
      "gave  |  give\n",
      "her  |  her\n",
      "baby  |  baby\n",
      "a  |  a\n",
      "red  |  red\n",
      "apple  |  apple\n",
      ".  |  .\n",
      "The  |  the\n",
      "baby  |  baby\n",
      "tried  |  try\n",
      "to  |  to\n",
      "eat  |  eat\n",
      "the  |  the\n",
      "apple  |  apple\n",
      ".  |  .\n",
      "His  |  his\n",
      "mouth  |  mouth\n",
      "was  |  be\n",
      "too  |  too\n",
      "small  |  small\n",
      ".  |  .\n",
      "\n",
      "  |  \n",
      "\n",
      "And  |  and\n",
      "he  |  he\n",
      "did  |  do\n",
      "n’t  |  not\n",
      "have  |  have\n",
      "any  |  any\n",
      "teeth  |  tooth\n",
      ".  |  .\n",
      "His  |  his\n",
      "brother  |  brother\n",
      "took  |  take\n",
      "the  |  the\n",
      "apple  |  apple\n",
      ".  |  .\n",
      "His  |  his\n",
      "brother  |  brother\n",
      "ate  |  eat\n",
      "the  |  the\n",
      "apple  |  apple\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('''The mother gave her baby a red apple. The baby tried to eat the apple. His mouth was too small.\n",
    "And he didn’t have any teeth. His brother took the apple. His brother ate the apple.''')\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782d8bec-2982-48b1-9f8d-a46a29fbae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customize behaviour\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e3f6b2-05ad-4157-b5a6-47dd37f82821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  bro\n",
      ",  |  ,\n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brah\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e86a4624-d59d-4701-9ee2-f30f977370fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  Brother\n",
      ",  |  ,\n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brother\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "#so we add attribute ruler\n",
    "\n",
    "\n",
    "ar = nlp.get_pipe(\"attribute_ruler\")\n",
    "\n",
    "ar.add([[{\"TEXT\":\"Bro\"}], [{\"TEXT\":\"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b0f29-4f99-43de-99b0-80ae8343f26d",
   "metadata": {},
   "source": [
    "Now it's working & showing as Brpther for \"Bro\" and \"Brah\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8d767-a657-4cc8-bf4d-353e89459f77",
   "metadata": {},
   "source": [
    "<h2>Tasks</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411c589-425b-4128-ba50-d283fe8ed965",
   "metadata": {},
   "source": [
    "**Exercise1:**\n",
    "\n",
    "* Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
    "* Write a short note on the words that have different base words using stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "534294f9-94e6-47b5-8eb0-c34a220fce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  like\n",
      "children  |  children\n",
      "whom  |  whom\n",
      "good  |  good\n",
      "ate  |  ate\n",
      "fishing  |  fish\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "\n",
    "for word in lst_words:\n",
    "    print(word ,\" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a6fce27-33e3-4ea7-813a-3d3d9719b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  likely\n",
      "children  |  child\n",
      "who  |  who\n",
      "good  |  good\n",
      "ate  |  eat\n",
      "fishing  |  fishing\n"
     ]
    }
   ],
   "source": [
    "#lemmetization \n",
    "\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bacaa64-f95b-4476-b6ed-dc3591ffc2e6",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "* Words that are different in stemming and lemmatization are:\n",
    "\n",
    "    * painting\n",
    "    * likely\n",
    "    * children\n",
    "    * ate\n",
    "    * fishing\n",
    "\n",
    "* As Stemming achieves the base word by removing the suffixes [ing, ly etc], so it successfully transform the words like 'painting', 'likely', 'fishing' and lemmatization fails for some words ending with suffixes here.\n",
    "\n",
    "* As Lemmatization uses the dictionary meanings while converting to the base form, so words like 'children' and 'ate' are successfully transformed and stemming fails here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386a731-9ea5-477c-86a5-58de5b444a44",
   "metadata": {},
   "source": [
    "**Exercise2:**\n",
    "\n",
    "* convert the given text into it's base form using both stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "483251a1-1ab3-471a-9190-1586380e456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8eddacc0-29bb-446c-8930-cf8328b5455d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "\n",
    "#step 1: Word tokenizing\n",
    "#words = list(text.split(\" \")) #we can use this also\n",
    "all_word_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "#step2: getting the base form for each token using stemmer\n",
    "\n",
    "stemmed_words = []\n",
    "\n",
    "for word in all_word_tokens:\n",
    "    stemmed_words.append(stemmer.stem(word))\n",
    "\n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "\n",
    "\" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2e1f8e5-476d-49f4-8b3c-45d42ba802f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \\n habit of fishing and swim too . besides all this , she be a wonderful at cook too . \\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "\n",
    "#step1: Creating the object for the given text\n",
    "doc = nlp(text)\n",
    "\n",
    "#step2: getting the base form for each token using spacy 'lemma_'\n",
    "\n",
    "after_lemma = []\n",
    "\n",
    "for token in doc:\n",
    "    after_lemma.append(token.lemma_)\n",
    "\n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "\n",
    "\" \".join(after_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c5030-2bba-440c-974b-985ecacac2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
